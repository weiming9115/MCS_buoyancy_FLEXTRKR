{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21476cb0-9411-45f6-b7d0-384215e71d3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63195832-ed7b-4673-ac0e-ea45b1a994d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82f087cb-ad3d-4ce0-ad8d-4d80ff661b6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set fonts configuration - Arial\n",
    "matplotlib.rcParams['font.family'] = \"Open Sans\"\n",
    "matplotlib.rcParams['font.sans-serif'] = \"Arial\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72603e01-b556-4e7f-a733-08c8729025db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_tracks_phase(data_tracks, var_name):\n",
    "    \"\"\"\n",
    "    return area-related variables \n",
    "    \"\"\"\n",
    "    var_list = []\n",
    "    track_list = []\n",
    "    \n",
    "    for track in data_tracks.tracks.values:\n",
    "\n",
    "        track_list.append(track)\n",
    "        tmp = data_tracks.sel(tracks=track)\n",
    "        phase_list = [tmp.idt_mcs_init.values, tmp.idt_mcs_grow.values, tmp.idt_mcs_mature.values,\n",
    "                      tmp.idt_mcs_decay.values, tmp.idt_mcs_end.values]\n",
    "\n",
    "        ds = xr.Dataset(data_vars=dict(var_null=(['mcs_phase'], tmp[var_name].sel(times=phase_list).values)),\n",
    "                        coords=dict(mcs_phase=(['mcs_phase'],['Init', 'Grow', 'Mature', 'Decay', 'End'])))\n",
    "\n",
    "        var_list.append(ds)\n",
    "\n",
    "    ds_xr = xr.concat(var_list, pd.Index(track_list, name='tracks')).rename_vars({'var_null':var_name})\n",
    "        \n",
    "    return ds_xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e3d1c41-76a0-4f97-9979-3cdd55392d47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_tracks_BL_features(files):\n",
    "    \"\"\"\n",
    "    return tracks by BL_TOT bins (unit: K)\n",
    "    \"\"\"\n",
    "    \n",
    "    track_list = []\n",
    "    BL_features_list = []    \n",
    "        \n",
    "    for file in files:\n",
    "        \n",
    "        track_list.append(int(file.name[-11:-6])) # save track number \n",
    "        \n",
    "        tmp = xr.open_dataset(file)\n",
    "        # calculate BL+ fraction and BL+ amplitude\n",
    "        BL_mcs = tmp.Buoy_TOT.where(tmp.cloudtracknumber_nomergesplit > 0)\n",
    "        BL_pos = BL_mcs.where(BL_mcs > 0, 0)\n",
    "        BL_pos_nan = BL_mcs.where(BL_mcs > 0, np.nan)\n",
    "        BL_pos_binary = BL_pos.where(BL_pos ==0, 1)\n",
    "        mcs_area = tmp.cloudtracknumber_nomergesplit.sum(('x','y'))\n",
    "        BL_pos_area = BL_pos_binary.sum(('x','y')).rename('BL_positive_area')\n",
    "        BL_pos_frac = (BL_pos_area/mcs_area).rename('BL_positive_fraction')\n",
    "        BL_tot_bp = BL_pos_nan.mean(('x','y')).rename('BL_TOT_bp')\n",
    "        \n",
    "        # BL estimates, MCS grids\n",
    "        BL_tot_mcs = tmp.Buoy_TOT.where(tmp.cloudtracknumber_nomergesplit > 0).mean(('x','y')).rename('BL_TOT_mcs')\n",
    "        BL_cape_mcs = tmp.Buoy_CAPE.where(tmp.cloudtracknumber_nomergesplit > 0).mean(('x','y')).rename('BL_CAPE_mcs')\n",
    "        BL_subsat_mcs = tmp.Buoy_SUBSAT.where(tmp.cloudtracknumber_nomergesplit > 0).mean(('x','y')).rename('BL_SUBSAT_mcs')\n",
    "    \n",
    "        # BL estimates, non-MCS grids\n",
    "        BL_tot_ouside = tmp.Buoy_TOT.where(tmp.cloudtracknumber_nomergesplit == 0).mean(('x','y')).rename('BL_TOT_outside')\n",
    "        BL_cape_ouside = tmp.Buoy_CAPE.where(tmp.cloudtracknumber_nomergesplit == 0).mean(('x','y')).rename('BL_CAPE_outside')\n",
    "        BL_subsat_ouside = tmp.Buoy_SUBSAT.where(tmp.cloudtracknumber_nomergesplit == 0).mean(('x','y')).rename('BL_SUBSAT_outside')        \n",
    "        \n",
    "        # BL estimates, 5-deg. mean\n",
    "        BL_tot_5deg = tmp.Buoy_TOT.sel(x=slice(15,25),y=slice(15,25)).mean(('x','y')).rename('BL_TOT_amean')\n",
    "        BL_cape_5deg = tmp.Buoy_CAPE.sel(x=slice(15,25),y=slice(15,25)).mean(('x','y')).rename('BL_CAPE_amean')\n",
    "        BL_subsat_5deg = tmp.Buoy_SUBSAT.sel(x=slice(15,25),y=slice(15,25)).mean(('x','y')).rename('BL_SUBSAT_amean')\n",
    "        \n",
    "        # replace 0 by nan to avoid incorrectness when doing averaging\n",
    "        BL_pos_area = BL_pos_area.where(BL_pos_area > 0, np.nan)\n",
    "        BL_pos_frac = BL_pos_frac.where(BL_pos_frac > 0, np.nan)\n",
    "        \n",
    "        BL_features_list.append(xr.merge([BL_pos_area, BL_pos_frac, BL_tot_bp, BL_tot_mcs,\n",
    "                                         BL_cape_mcs, BL_subsat_mcs, BL_tot_ouside,\n",
    "                                         BL_cape_ouside, BL_subsat_ouside,\n",
    "                                         BL_tot_5deg, BL_cape_5deg, BL_subsat_5deg]))\n",
    "    \n",
    "    BL_features_xr = xr.concat(BL_features_list, pd.Index(track_list, name='tracks'))\n",
    "    \n",
    "    return BL_features_xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed622f9e-8bfa-4230-a478-49e83d349838",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_tracks_precip_features(files):\n",
    "    \"\"\"\n",
    "    return tracks by BL_TOT bins (unit: K)\n",
    "    \"\"\"\n",
    "    \n",
    "    track_list = []\n",
    "    precip_features_list = []    \n",
    "    corr_coeff_temp = []\n",
    "        \n",
    "    for file in files:\n",
    "        \n",
    "        track_list.append(int(file.name[-11:-6])) # save track number \n",
    "        \n",
    "        tmp = xr.open_dataset(file)\n",
    "        # calculate precip amplitude within mcs\n",
    "        prec_mcs = tmp.precipitationCal.where(tmp.cloudtracknumber_nomergesplit > 0)\n",
    "        mtpr_mcs = tmp.mtpr.where(tmp.cloudtracknumber_nomergesplit > 0)\n",
    "        prec_amp_mcs = prec_mcs.mean(('x','y')).rename('precipitationCal_mcs')\n",
    "        mtpr_amp_mcs = mtpr_mcs.mean(('x','y')).rename('mtpr_mcs')\n",
    "        \n",
    "        try:\n",
    "            # estimate spatial correlation \n",
    "            corr_coeff = []\n",
    "            for phase in tmp.mcs_phase:\n",
    "                prec_era5 = prec_mcs.sel(mcs_phase=phase)\n",
    "                prec_gpm = mtpr_mcs.sel(mcs_phase=phase)\n",
    "                \n",
    "                x1 = np.where(np.isnan(prec_era5.values.ravel())==0)[0]\n",
    "                x2 = np.where(np.isnan(prec_era5.values.ravel())==0)[0]\n",
    "                idx = np.intersect1d(x1,x2)\n",
    "\n",
    "                stats = pearsonr(prec_era5.values.ravel()[idx], prec_gpm.values.ravel()[idx])\n",
    "                corr_coeff.append(stats[0]) # save correlation coefficient \n",
    "            corr_coeff_space = xr.Dataset(data_vars=dict(corr_coeff_space=(['mcs_phase'],np.asarray(corr_coeff))),\n",
    "                                     coords=dict(mcs_phase=(['mcs_phase'], tmp.mcs_phase.values)))\n",
    "\n",
    "            # estimate temporal correlation \n",
    "            corr_coeff_temp.append(pearsonr(prec_amp_mcs.values.ravel(), mtpr_amp_mcs.values.ravel())[0])\n",
    "\n",
    "            precip_features_list.append(xr.merge([prec_amp_mcs ,mtpr_amp_mcs,\n",
    "                                                  corr_coeff_space]))\n",
    "        except:\n",
    "            # if nan in dataset (one file in 2009...) \n",
    "            corr_coeff = [np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "            corr_coeff_space = xr.Dataset(data_vars=dict(corr_coeff_space=(['mcs_phase'],np.asarray(corr_coeff))),\n",
    "                                     coords=dict(mcs_phase=(['mcs_phase'], tmp.mcs_phase.values)))\n",
    "\n",
    "            # estimate temporal correlation \n",
    "            corr_coeff_temp.append(np.nan)\n",
    "\n",
    "            precip_features_list.append(xr.merge([prec_amp_mcs ,mtpr_amp_mcs,\n",
    "                                                  corr_coeff_space]))\n",
    "            \n",
    "            print('error file: {}'.format(file))\n",
    "            #exit()\n",
    "    \n",
    "    corr_coeff_temp_xr = xr.Dataset(data_vars=dict(corr_coeff_temp=(['tracks'],np.asarray(corr_coeff_temp))),\n",
    "                                 coords=dict(tracks=(['tracks'], track_list)))\n",
    "    precip_features_xr = xr.concat(precip_features_list, pd.Index(track_list, name='tracks'))\n",
    "\n",
    "    # merge two datasets\n",
    "    precip_features_xr = xr.merge([precip_features_xr, corr_coeff_temp_xr])\n",
    "    \n",
    "    return precip_features_xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9c376a6-a7a9-4e28-83d6-e77f49a7705b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing year: 2001\n",
      "processing year: 2002\n",
      "processing year: 2003\n",
      "processing year: 2004\n",
      "processing year: 2005\n",
      "processing year: 2006\n",
      "CPU times: user 38min 11s, sys: 4min 45s, total: 42min 56s\n",
      "Wall time: 43min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "out_dir = Path('/scratch/wmtsai/temp_mcs/mcs_stats/mcs_tracks_non2mcs/tracks_area_mean')\n",
    "\n",
    "data_tracks_list = []\n",
    "\n",
    "year_list = np.arange(2001,2007)\n",
    "for year in year_list:\n",
    "\n",
    "    print('processing year: {}'.format(year))\n",
    "    # directory of the mcs_3dvars files\n",
    "    dir_envs_track = Path('/scratch/wmtsai/temp_mcs/mcs_stats/envs_track/{}/tropics_extend'.format(year))\n",
    "    files = sorted(list(dir_envs_track.glob('*.LD.nc')))\n",
    "\n",
    "    # load data_tracks \n",
    "    data_tracks = xr.open_dataset('/scratch/wmtsai/temp_mcs/mcs_stats/mcs_tracks_non2mcs/mcs_tracks_non2mcs_{}.tropics30NS.extend.nc'.format(year))\n",
    "    \n",
    "    # data_tracks time spend (1) from initial and mature (2) from mature to end\n",
    "    data_tracks['hours_ccs2init'] = data_tracks.idt_mcs_init - data_tracks.idt_ccs_init\n",
    "    data_tracks['hours_init2mat']  = data_tracks.idt_mcs_mature - data_tracks.idt_mcs_init\n",
    "    data_tracks['hours_mat2end']  = data_tracks.idt_mcs_end - data_tracks.idt_mcs_mature\n",
    "    \n",
    "    # write out BL_features dataset based on mcs_envs output\n",
    "    data_BL_features = data_tracks_BL_features(files)\n",
    "    data_precip_features = data_tracks_precip_features(files)\n",
    "    \n",
    "    # extract existing area-related variables\n",
    "    data_ccs_area = data_tracks_phase(data_tracks, var_name='ccs_area')\n",
    "    data_core_area = data_tracks_phase(data_tracks, var_name='core_area')\n",
    "    data_cold_area = data_tracks_phase(data_tracks, var_name='cold_area')\n",
    "    data_area_features = xr.merge([data_ccs_area, data_core_area, data_cold_area])\n",
    "    \n",
    "    corr_temp = data_precip_features.corr_coeff_temp\n",
    "    corr_coeff_space = data_precip_features.corr_coeff_space.mean('mcs_phase')\n",
    "\n",
    "    data_tracks_out = xr.merge([data_tracks['mcs_duration'],\n",
    "                                data_tracks['hours_init2mat'],\n",
    "                                data_tracks['hours_mat2end'],\n",
    "                                data_BL_features,\n",
    "                                data_precip_features,\n",
    "                                data_area_features]\n",
    "                                )\n",
    "    \n",
    "    data_tracks_out.to_netcdf(out_dir / 'featstats_tracks_non2mcs_{}.tropics30NS.extend.nc'.format(year))\n",
    "    \n",
    "    del data_tracks_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09387c3a-8d64-4343-b002-55c61e7259eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
